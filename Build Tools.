# GitHub Pages

_Create a site or blog from your GitHub repositories with GitHub Pages._

## Welcome

- **Who is this for**: Beginners, students, project maintainers, small businesses.
- **What you'll learn**: How to build a GitHub Pages site.
- **What you'll build**: We'll build a simple GitHub Pages site with a blog. We'll use [Jekyll](https://jekyllrb.com), a static site generator.
- **Prerequisites**: If you need to learn about branches, commits, and pull requests, take [Introduction to GitHub](https://github.com/skills/introduction-to-github) first.

- **How long**: This exercise takes less than one hour to complete.

In this exercise, you will:

1. Enable GitHub Pages
1. Configure your site
1. Customize your home page
1. Create a blog post
1. Merge your pull request


### How to start this exercise

Simply copy the exercise to your account, then give your favorite Octocat (Mona) **about 20 seconds** to prepare the first lesson, then **refresh the page**.

[![](https://img.shields.io/badge/Copy%20Exercise-%E2%86%92-1f883d?style=for-the-badge&logo=github&labelColor=197935)](https://github.com/new?template_owner=skills&template_name=github-pages&owner=%40me&name=skills-github-pages&description=Exercise:+Create+a+site+or+blog+from+your+GitHub+repositories+with+GitHub+Pages&visibility=public)

<details>
<summary>Having trouble? ü§∑</summary><br/>

When copying the exercise, we recommend the following settings:

- For owner, choose your personal account or an organization to host the repository.

- We recommend creating a public repository, since private repositories will use Actions minutes.

If the exercise isn't ready in 20 seconds, please check the [Actions](../../actions) tab.

- Check to see if a job is running. Sometimes it simply takes a bit longer.

- If the page shows a failed job, please submit an issue. Nice, you found a bug! üêõ

</details>

---

&copy; 2025 GitHub &bull; [Code of Conduct](https://www.contributor-covenant.org/version/2/1/code_of_conduct/code_of_conduct.md) &bull; [MIT License](https://gh.io/mit)

Build Tools.
Parcel.
Parcel
Backers on Open Collective Sponsors on Open Collective Build Status Coverage David Dependency Status npm package npm package Join the community on Spectrum Twitter Follow

Features
üöÄ Blazing fast bundle times - multicore compilation, and a filesystem cache for fast rebuilds even after a restart.
üì¶ Out of the box support for JS, CSS, HTML, file assets, and more - no plugins to install.
üê† Automatically transforms modules using Babel, PostCSS, and PostHTML when needed - even node_modules.
‚úÇÔ∏è Zero configuration code splitting using dynamic import() statements.
üî• Built in support for hot module replacement
üö® Friendly error logging experience - syntax highlighted code frames help pinpoint the problem.
Getting started
Install with yarn:
yarn global add parcel-bundler
or with npm:

npm install -g parcel-bundler
Parcel can take any type of file as an entry point, but a HTML or JavaScript file is a good place to start. If you link your main JavaScript file in the HTML using a relative path, Parcel will also process it for you, and replace the reference with a URL to the output file.
<html>
<body>
  <script src="./index.js"></script>
</body>
</html>
Parcel has a development server built in which will automatically rebuild your app as you change files and supports hot module replacement for fast development. Just point it at your entry file:
parcel index.html
Now open http://localhost:1234/ in your browser. If needed, you can also override the default port with the -p option. Add --open to automatically open a browser.
See parceljs.org for more documentation!

Benchmarks
Based on a reasonably sized app, containing 1726 modules, 6.5M uncompressed. Built on a 2016 MacBook Pro with 4 physical CPUs.

Bundler Time
browserify 22.98s
webpack 20.71s
parcel 9.98s
parcel - with cache 2.64s
Why parcel?
There are many web application bundlers out there with huge adoption, including webpack and browserify. So, why do we need another one? The main reasons are around developer experience.

Many bundlers are built around configuration and plugins, and it is not uncommon to see applications with upwards of 500 lines of configuration just to get things working. This configuration is not just tedious and time consuming, but is also hard to get right and must be duplicated for each application. Oftentimes, this can lead to sub-optimized apps shipping to production. parcel is designed to need zero configuration: just point it at the entry point of your application, and it does the right thing.

Existing bundlers are also very slow. Large applications with lots of files and many dependencies can take minutes to build, which is especially painful during development, when things change all the time. File watchers can help with rebuilds, but the initial launch is often still very slow.

parcel utilizes worker processes to compile your code in parallel, utilizing modern multicore processors. This results in a huge boost in speed for initial builds. It also has a file system cache, which saves the compiled results per file, for even faster subsequent startups.

Finally, existing bundlers are built around string loaders/transforms, where the transform takes in a string, parses it, does some transformation, and generates code again. Oftentimes, this ends up causing many parses and code generation runs on a single file, which is inefficient. Instead, parcel's transforms work on ASTs, so that there is one parse, many transforms, and one code generation per file.

How it works
parcel transforms a tree of assets into a tree of bundles. Many other bundlers are fundamentally based around JavaScript assets, with other formats tacked on - for example, by default inlined as strings into JS files. parcel is file-type agnostic - it will work with any type of assets the way you'd expect, with no configuration.

parcel takes as input a single entry asset, which could be any file type: JS, HTML, CSS, image, etc. There are various asset types defined in parcel which know how to handle specific file types. The assets are parsed, their dependencies are extracted, and they are transformed to their final compiled form. This creates a tree of assets.

Once the asset tree has been constructed, the assets are placed into a bundle tree. A bundle is created for the entry asset, and child bundles are created for dynamic imports, which cause code splitting to occur. Child bundles are also created when assets of a different type are imported. For example, if you imported a CSS file from JavaScript, it would be placed into a sibling bundle in correlation to the associated JavaScript file. If an asset is required in more than one bundle, it is hoisted up to the nearest common ancestor in the bundle tree, so it is not included more than once.

After the bundle tree is constructed, each bundle is written to a file by a packager specific to the file type. The packagers know how to combine the code from each asset together into the final file that is loaded by a browser.

Community
All feedback and suggestions are welcome!

üí¨ Join the community on Spectrum
üì£ Stay up to date on new features and announcements on @parceljs.
Contributors
This project exists thanks to all the people who contribute. [Contribute]. contributors

Backers
Thank you to all our backers! üôè [Become a backer]
         
Changelog
License
MIT.


Webpack.

npm

node builds1 dependency-review coverage PR's welcome compatibility-score downloads install-size backers sponsors contributors discussions discord

webpack
Webpack is a module bundler. Its main purpose is to bundle JavaScript files for usage in a browser, yet it is also capable of transforming, bundling, or packaging just about any resource or asset.

Table of Contents
Install
Introduction
Concepts
Contributing
Support
Current project members
TSC (Technical Steering Committee)
Core Collaborators
Sponsoring
Premium Partners
Gold Sponsors
Silver Sponsors
Bronze Sponsors
Backers
Special Thanks
Install
Install with npm:

npm install --save-dev webpack
Install with yarn:

yarn add webpack --dev
Introduction
Webpack is a bundler for modules. The main purpose is to bundle JavaScript files for usage in a browser, yet it is also capable of transforming, bundling, or packaging just about any resource or asset.

TL;DR

Bundles ES Modules, CommonJS, and AMD modules (even combined).
Can create a single bundle or multiple chunks that are asynchronously loaded at runtime (to reduce initial loading time).
Dependencies are resolved during compilation, reducing the runtime size.
Loaders can preprocess files while compiling, e.g. TypeScript to JavaScript, Handlebars strings to compiled functions, images to Base64, etc.
Highly modular plugin system to do whatever else your application requires.
Learn about webpack through videos!
Understanding Webpack - Video 1
Understanding Webpack - Video 2
Get Started
Check out webpack's quick Get Started guide and the other guides.

Browser Compatibility
Webpack supports all browsers that are ES5-compliant (IE8 and below are not supported). Webpack also needs Promise for import() and require.ensure(). If you want to support older browsers, you will need to load a polyfill before using these expressions.

Concepts
Plugins
Webpack has a rich plugin interface. Most of the features within webpack itself use this plugin interface. This makes webpack very flexible.

Name Status Install Size Description
mini-css-extract-plugin mini-css-npm mini-css-size Extracts CSS into separate files. It creates a CSS file per JS file which contains CSS.
compression-webpack-plugin compression-npm compression-size Prepares compressed versions of assets to serve them with Content-Encoding
html-bundler-webpack-plugin bundler-npm bundler-size Renders a template (EJS, Handlebars, Pug) with referenced source asset files into HTML.
html-webpack-plugin html-plugin-npm html-plugin-size Simplifies creation of HTML files (index.html) to serve your bundles
pug-plugin pug-plugin-npm pug-plugin-size Renders Pug files to HTML, extracts JS and CSS from sources specified directly in Pug.
Loaders
Webpack enables the use of loaders to preprocess files. This allows you to bundle any static resource way beyond JavaScript. You can easily write your own loaders using Node.js.

Loaders are activated by using loadername! prefixes in require() statements, or are automatically applied via regex from your webpack configuration.

Files
Name Status Install Size Description
val-loader val-npm val-size Executes code as module and considers exports as JS code
JSON
Name Status Install Size Description
 cson-npm cson-size Loads and transpiles a CSON file
Transpiling
Name Status Install Size Description
babel-loader babel-npm babel-size Loads ES2015+ code and transpiles to ES5 using Babel
 type-npm type-size Loads TypeScript like JavaScript
 coffee-npm coffee-size Loads CoffeeScript like JavaScript
Templating
Name Status Install Size Description
 html-npm html-size Exports HTML as string, requires references to static resources
 pug-npm pug-size Loads Pug templates and returns a function
 pug3-npm pug3-size Compiles Pug to a function or HTML string, useful for use with Vue, React, Angular
 md-npm md-size Compiles Markdown to HTML
 posthtml-npm posthtml-size Loads and transforms a HTML file using PostHTML
 hbs-npm hbs-size Compiles Handlebars to HTML
Styling
Name Status Install Size Description
<style> style-npm style-size Add exports of a module as style to DOM
 css-npm css-size Loads CSS file with resolved imports and returns CSS code
 less-npm less-size Loads and compiles a LESS file
 sass-npm sass-size Loads and compiles a Sass/SCSS file
 stylus-npm stylus-size Loads and compiles a Stylus file
 postcss-npm postcss-size Loads and transforms a CSS/SSS file using PostCSS
Frameworks
Name Status Install Size Description
 vue-npm vue-size Loads and compiles Vue Components
 polymer-npm polymer-size Process HTML & CSS with preprocessor of choice and require() Web Components like first-class modules
 angular-npm angular-size Loads and compiles Angular 2 Components
 riot-npm riot-size Riot official webpack loader
 svelte-npm svelte-size Official Svelte loader
Performance
Webpack uses async I/O and has multiple caching levels. This makes webpack fast and incredibly fast on incremental compilations.

Module Formats
Webpack supports ES2015+, CommonJS and AMD modules out of the box. It performs clever static analysis on the AST of your code. It even has an evaluation engine to evaluate simple expressions. This allows you to support most existing libraries out of the box.

Code Splitting
Webpack allows you to split your codebase into multiple chunks. Chunks are loaded asynchronously at runtime. This reduces the initial loading time.

Optimizations
Webpack can do many optimizations to reduce the output size of your JavaScript by deduplicating frequently used modules, minifying, and giving you full control of what is loaded initially and what is loaded at runtime through code splitting. It can also make your code chunks cache friendly by using hashes.

Contributing
We want contributing to webpack to be fun, enjoyable, and educational for anyone, and everyone. We have a vibrant ecosystem that spans beyond this single repo. We welcome you to check out any of the repositories in our organization or webpack-contrib organization which houses all of our loaders and plugins.

Contributions go far beyond pull requests and commits. Although we love giving you the opportunity to put your stamp on webpack, we also are thrilled to receive a variety of other contributions including:

Documentation updates, enhancements, designs, or bugfixes
Spelling or grammar fixes
README.md corrections or redesigns
Adding unit, or functional tests
Triaging GitHub issues -- especially determining whether an issue still persists or is reproducible.
Searching #webpack on twitter and helping someone else who needs help
Teaching others how to contribute to one of the many webpack's repos!
Blogging, speaking about, or creating tutorials about one of webpack's many features.
Helping others in our webpack gitter channel.
The Contributor's Guide to webpack
To get started have a look at our documentation on contributing.

Creating your own plugins and loaders
If you create a loader or plugin, we would <3 for you to open source it, and put it on npm. We follow the x-loader, x-webpack-plugin naming convention.

Support
We consider webpack to be a low-level tool used not only individually but also layered beneath other awesome tools. Because of its flexibility, webpack isn't always the easiest entry-level solution, however we do believe it is the most powerful. That said, we're always looking for ways to improve and simplify the tool without compromising functionality. If you have any ideas on ways to accomplish this, we're all ears!

If you're just getting started, take a look at our new docs and concepts page. This has a high level overview that is great for beginners!!

If you have discovered a üêú or have a feature suggestion, feel free to create an issue on GitHub.

Current project members
For information about the governance of the Node.js project, see GOVERNANCE.md.

TSC (Technical Steering Committee)
alexander-akait - Alexander Akait <sheo13666q@gmail.com> (he/him)
evenstensberg - Even Stensberg <evenstensberg@gmail.com> (he/him)
ovflowd - Claudio Wunder <cwunder@gnome.org> (he/they)
snitin315 - Nitin Kumar <snitin315@gmail.com> (he/him)
thelarkinn - Sean Larkin <selarkin@microsoft.com> (he/him)
Core Collaborators
jhnns - Johannes Ewald <mail@johannesewald.de>
sokra - Tobias Koppers <jackworks@protonmail.co>
spacek33z - Kees Kluskens <kees@webduck.nl>
TheLarkInn - Sean T. Larkin <selarkin@microsoft.com>
Sponsoring
Most of the core team members, webpack contributors and contributors in the ecosystem do this open source work in their free time. If you use webpack for a serious task, and you'd like us to invest more time on it, please donate. This project increases your income/productivity too. It makes development and applications faster and it reduces the required bandwidth.

This is how we use the donations:

Allow the core team to work on webpack
Thank contributors if they invested a large amount of time in contributing
Support projects in the ecosystem that are of great value for users
Support projects that are voted most (work in progress)
Infrastructure cost
Fees for money handling
Premium Partners

Other Backers and Sponsors
Before we started using OpenCollective, donations were made anonymously. Now that we have made the switch, we would like to acknowledge these sponsors (and the ones who continue to donate using OpenCollective). If we've missed someone, please send us a PR, and we'll add you to this list.

Angular MoonMail MONEI

Gold Sponsors
Become a gold sponsor and get your logo on our README on GitHub with a link to your site.
                           
Silver Sponsors
Become a silver sponsor and get your logo on our README on GitHub with a link to your site.
                         
Bronze Sponsors
Become a bronze sponsor and get your logo on our README on GitHub with a link to your site.                                                                                               
Backers
Become a backer and get your image on our README on GitHub with a link to your site.                                                                                                  
(In chronological order)

@google for Google Web Toolkit (GWT), which aims to compile Java to JavaScript. It features a similar Code Splitting as webpack.
@medikoo for modules-webmake, which is a similar project. webpack was born because of the desire for code splitting for modules such as Webmake. Interestingly, the Code Splitting issue is still open (thanks also to @Phoscur for the discussion).
@substack for browserify, which is a similar project and source for many ideas.
@jrburke for require.js, which is a similar project and source for many ideas.
@defunctzombie for the browser-field spec, which makes modules available for node.js, browserify and webpack.
@sokra for creating webpack.
Every early webpack user, which contributed to webpack by writing issues or PRs. You influenced the direction.
All past and current webpack maintainers and collaborators.
Everyone who has written a loader for webpack. You are the ecosystem...
Everyone not mentioned here but that has also influenced webpack.

Rollup.

npm version node compatibility install size code coverage backers sponsors license Join the chat at https://is.gd/rollup_chat

Rollup
Overview
Rollup is a module bundler for JavaScript which compiles small pieces of code into something larger and more complex, such as a library or application. It uses the standardized ES module format for code, instead of previous idiosyncratic solutions such as CommonJS and AMD. ES modules let you freely and seamlessly combine the most useful individual functions from your favorite libraries. Rollup can optimize ES modules for faster native loading in modern browsers, or output a legacy module format allowing ES module workflows today.

Quick Start Guide
Install with npm install --global rollup. Rollup can be used either through a command line interface with an optional configuration file or else through its JavaScript API. Run rollup --help to see the available options and parameters. The starter project templates, rollup-starter-lib and rollup-starter-app, demonstrate common configuration options, and more detailed instructions are available throughout the user guide.

Commands
These commands assume the entry point to your application is named main.js, and that you'd like all imports compiled into a single file named bundle.js.

For browsers:

# compile to a <script> containing a self-executing function
rollup main.js --format iife --name "myBundle" --file bundle.js
For Node.js:

# compile to a CommonJS module
rollup main.js --format cjs --file bundle.js
For both browsers and Node.js:

# UMD format requires a bundle name
rollup main.js --format umd --name "myBundle" --file bundle.js
Why
Developing software is usually easier if you break your project into smaller separate pieces, since that often removes unexpected interactions and dramatically reduces the complexity of the problems you'll need to solve, and simply writing smaller projects in the first place isn't necessarily the answer. Unfortunately, JavaScript has not historically included this capability as a core feature in the language.

This finally changed with ES modules support in JavaScript, which provides a syntax for importing and exporting functions and data so they can be shared between separate scripts. Most browsers and Node.js support ES modules. However, Node.js releases before 12.17 support ES modules only behind the --experimental-modules flag, and older browsers like Internet Explorer do not support ES modules at all. Rollup allows you to write your code using ES modules, and run your application even in environments that do not support ES modules natively. For environments that support them, Rollup can output optimized ES modules; for environments that don't, Rollup can compile your code to other formats such as CommonJS modules, AMD modules, and IIFE-style scripts. This means that you get to write future-proof code, and you also get the tremendous benefits of...

Tree Shaking
In addition to enabling the use of ES modules, Rollup also statically analyzes and optimizes the code you are importing, and will exclude anything that isn't actually used. This allows you to build on top of existing tools and modules without adding extra dependencies or bloating the size of your project.

For example, with CommonJS, the entire tool or library must be imported.

// import the entire utils object with CommonJS
var utils = require('node:utils');
var query = 'Rollup';
// use the ajax method of the utils object
utils.ajax('https://api.example.com?search=' + query).then(handleResponse);
But with ES modules, instead of importing the whole utils object, we can just import the one ajax function we need:

// import the ajax function with an ES import statement
import { ajax } from 'node:utils';

var query = 'Rollup';
// call the ajax function
ajax('https://api.example.com?search=' + query).then(handleResponse);
Because Rollup includes the bare minimum, it results in lighter, faster, and less complicated libraries and applications. Since this approach is based on explicit import and export statements, it is vastly more effective than simply running an automated minifier to detect unused variables in the compiled output code.

Compatibility
Importing CommonJS
Rollup can import existing CommonJS modules through a plugin.

Publishing ES Modules
To make sure your ES modules are immediately usable by tools that work with CommonJS such as Node.js and webpack, you can use Rollup to compile to UMD or CommonJS format, and then point to that compiled version with the main property in your package.json file. If your package.json file also has a module field, ES-module-aware tools like Rollup and webpack will import the ES module version directly.

Contributors
This project exists thanks to all the people who contribute. [Contribute]. . If you want to contribute yourself, head over to the contribution guidelines.

Backers
Thank you to all our backers! üôè [Become a backer]


Special Sponsor
TNG Logo

TNG has been supporting the work of Lukas Taegert-Atkinson on Rollup since 2017.

License
MIT.


Gulp.

The streaming build system

NPM version Downloads Build Status Coveralls Status

gulp.
Automation - gulp is a toolkit that helps you automate painful or time-consuming tasks in your development workflow.
Platform-agnostic - Integrations are built into all major IDEs and people are using gulp with PHP, .NET, Node.js, Java, and other platforms.
Strong Ecosystem - Use npm modules to do anything you want + over 3000 curated plugins for streaming file transformations.
Simple - By providing only a minimal API surface, gulp is easy to learn and simple to use.
Installation
Follow our Quick Start guide.

Roadmap
Find out about all our work-in-progress and outstanding issues at https://github.com/orgs/gulpjs/projects.

Documentation
Check out the Getting Started guide and API docs on our website!

Excuse our dust! All other docs will be behind until we get everything updated. Please open an issue if something isn't working.

Sample gulpfile.js
This file will give you a taste of what gulp does.

var gulp = require('gulp');
var less = require('gulp-less');
var babel = require('gulp-babel');
var concat = require('gulp-concat');
var uglify = require('gulp-uglify');
var rename = require('gulp-rename');
var cleanCSS = require('gulp-clean-css');
var del = require('del');

var paths = {
  styles: {
    src: 'src/styles/**/*.less',
    dest: 'assets/styles/'
  },
  scripts: {
    src: 'src/scripts/**/*.js',
    dest: 'assets/scripts/'
  }
};

/* Not all tasks need to use streams, a gulpfile is just another node program
 * and you can use all packages available on npm, but it must return either a
 * Promise, a Stream or take a callback and call it
 */
function clean() {
  // You can use multiple globbing patterns as you would with `gulp.src`,
  // for example if you are using del 2.0 or above, return its promise
  return del([ 'assets' ]);
}

/*
 * Define our tasks using plain functions
 */
function styles() {
  return gulp.src(paths.styles.src)
    .pipe(less())
    .pipe(cleanCSS())
    // pass in options to the stream
    .pipe(rename({
      basename: 'main',
      suffix: '.min'
    }))
    .pipe(gulp.dest(paths.styles.dest));
}

function scripts() {
  return gulp.src(paths.scripts.src, { sourcemaps: true })
    .pipe(babel())
    .pipe(uglify())
    .pipe(concat('main.min.js'))
    .pipe(gulp.dest(paths.scripts.dest));
}

function watch() {
  gulp.watch(paths.scripts.src, scripts);
  gulp.watch(paths.styles.src, styles);
}

/*
 * Specify if tasks run in series or parallel using `gulp.series` and `gulp.parallel`
 */
var build = gulp.series(clean, gulp.parallel(styles, scripts));

/*
 * You can use CommonJS `exports` module notation to declare tasks
 */
exports.clean = clean;
exports.styles = styles;
exports.scripts = scripts;
exports.watch = watch;
exports.build = build;
/*
 * Define default task that can be called by just running `gulp` from cli
 */
exports.default = build;
Use latest JavaScript version in your gulpfile
Gulp provides a wrapper that will be loaded in your ESM code, so you can name your gulpfile as gulpfile.mjs or with "type": "module" specified in your package.json file.

And here's the same sample from above written in ESNext.

import { src, dest, watch } from 'gulp';
import less from 'gulp-less';
import babel from 'gulp-babel';
import concat from 'gulp-concat';
import uglify from 'gulp-uglify';
import rename from 'gulp-rename';
import cleanCSS from 'gulp-clean-css';
import del from 'del';

const paths = {
  styles: {
    src: 'src/styles/**/*.less',
    dest: 'assets/styles/'
  },
  scripts: {
    src: 'src/scripts/**/*.js',
    dest: 'assets/scripts/'
  }
};

/*
 * For small tasks you can export arrow functions
 */
export const clean = () => del([ 'assets' ]);

/*
 * You can also declare named functions and export them as tasks
 */
export function styles() {
  return src(paths.styles.src)
    .pipe(less())
    .pipe(cleanCSS())
    // pass in options to the stream
    .pipe(rename({
      basename: 'main',
      suffix: '.min'
    }))
    .pipe(dest(paths.styles.dest));
}

export function scripts() {
  return src(paths.scripts.src, { sourcemaps: true })
    .pipe(babel())
    .pipe(uglify())
    .pipe(concat('main.min.js'))
    .pipe(dest(paths.scripts.dest));
}

 /*
  * You could even use `export as` to rename exported tasks
  */
function watchFiles() {
  watch(paths.scripts.src, scripts);
  watch(paths.styles.src, styles);
}
export { watchFiles as watch };

const build = gulp.series(clean, gulp.parallel(styles, scripts));
/*
 * Export a default task
 */
export default build;
Incremental Builds
You can filter out unchanged files between runs of a task using the gulp.src function's since option and gulp.lastRun:

const paths = {
  ...
  images: {
    src: 'src/images/**/*.{jpg,jpeg,png}',
    dest: 'build/img/'
  }
}

function images() {
  return gulp.src(paths.images.src, {since: gulp.lastRun(images)})
    .pipe(imagemin())
    .pipe(gulp.dest(paths.images.dest));
}

function watch() {
  gulp.watch(paths.images.src, images);
}
Task run times are saved in memory and are lost when gulp exits. It will only save time during the watch task when running the images task for a second time.


Broccoli.

Broccoli

Build Status

A fast, reliable asset pipeline, supporting constant-time rebuilds and compact build definitions. Comparable to the Rails asset pipeline in scope, though it runs on Node and is backend-agnostic.

For more information and guides/documentation, checkout broccoli.build

For background and architecture, see the introductory blog post.

For the command line interface, see broccoli-cli.

Installation
npm install --save-dev broccoli
npm install --global broccoli-cli
Brocfile.js
A Brocfile.js file in the project root contains the build specification. It should export a function that returns a tree. Note: the Brocfile historically could export a tree/string directly, however this is now deprecated in favor of a function that can receive options

A tree can be any string representing a directory path, like 'app' or 'src'. Or a tree can be an object conforming to the Plugin API Specification. A Brocfile.js will usually directly work with only directory paths, and then use the plugins in the Plugins section to generate transformed trees.

The following simple Brocfile.js would export the app/ subdirectory as a tree:

export default () => 'app';
With that Brocfile, the build result would equal the contents of the app tree in your project folder. For example, say your project contains these files:

app
‚îú‚îÄ main.js
‚îî‚îÄ helper.js
Brocfile.js
package.json
‚Ä¶
Running broccoli build the-output (a command provided by broccoli-cli) would generate the following folder within your project folder:

the-output
‚îú‚îÄ main.js
‚îî‚îÄ helper.js
Options
The function that is exported from module.exports is passed an options hash by Broccoli that can be used when assembling the build.

The options hash is populated by the CLI environment when running broccoli build or broccoli serve. It currently only accepts a single option --environment, which is passed as env in the options hash.

Additionally --prod and --dev are available aliases to --environment=production and --environment=development respectively.

options:
env: Defaults to development, and can be overridden with the CLI argument --environment=X
For example:

export default (options) => {
    // tree = ... assemble tree

    // In production environment, minify the files
    if (options.env === 'production') {
        tree = minify(tree);
    }

    return tree;
}
TypeScript Support
A Brocfile.ts can be used in place of a Brocfile.js and Broccoli will automatically parse this through ts-node to provide TypeScript support. This allows developers to leverage type information when assembling a build pipeline. By default, Broccoli provides type information for the options object passed to the build function.

import { BrocfileOptions } from 'broccoli';

export default (options: BrocfileOptions) => {
  // tree = ... assemble tree

  // In production environment, minify the files
  if (options.env === 'production') {
    tree = minify(tree);
  }

  return tree;
};

Typescript by default only allows the ES6 modules import/export syntax to work when importing ES6 modules. In order to import a CommonJS module (one that uses require() or module.exports, you must use the following syntax:

import foo = require('foo');

export = 'bar';
You'll note the syntax is slightly different from the ESM syntax, but reads fairly well.

Using plugins in a Brocfile.js
The following Brocfile.js exports the app/ subdirectory as appkit/:

// Brocfile.js
import Funnel from 'broccoli-funnel';

export default () => new Funnel('app', {
  destDir: 'appkit'
})
Broccoli supports ES6 modules via esm for Brocfile.js. Note, TypeScript requires the use of a different syntax, see the TypeScript section above.

You can also use regular CommonJS require and module.exports if you prefer, however ESM is the future of Node, and the recommended syntax to use.

That example uses the plugin broccoli-funnel. In order for the import call to work, you must first put the plugin in your devDependencies and install it, with

npm install --save-dev broccoli-funnel
With the above Brocfile.js and the file tree from the previous example, running broccoli build the-output would generate the following folder:

the-output
‚îî‚îÄ appkit
   ‚îú‚îÄ main.js
   ‚îî‚îÄ helper.js
Plugins
You can find plugins under the broccoli-plugin keyword on npm.

Using Broccoli Programmatically
In addition to using Broccoli via the combination of broccoli-cli and a Brocfile.js, you can also use Broccoli programmatically to construct your own build output via the Builder class. The Builder is one of the core APIs in Broccoli, and is responsible for taking a graph of Broccoli nodes and producing an actual build artifact (i.e. the output usually found in your dist directory after you run broccoli build). The output of a Builder's build method is a Promise that resolves when all the operations in the graph are complete. You can use this promise to chain together additional operations (such as error handling or cleanup) that will execute once the build step is complete.

By way of example, let's assume we have a graph of Broccoli nodes constructed via a combination of Funnel and MergeTrees:

// non Brocfile.js, regular commonjs
const Funnel = require('broccoli-funnel');
const MergeTrees = require('broccoli-merge-trees');

const html = new Funnel(appRoot, {
  files: ['index.html'],
  annotation: 'Index file'
})

const js = new Funnel(appRoot, {
  files: ['app.js'],
  destDir: '/assets',
  annotation: 'JS Files'
});

const css = new Funnel(appRoot, {
  srcDir: 'styles',
  files: ['app.css'],
  destDir: '/assets',
  annotation: 'CSS Files'
});

const public = new Funnel(appRoot, {
  annotation: 'Public Files'
});

const tree = new MergeTrees([html, js, css, public]);
At this point, tree is a graph of nodes, each of which can represent either an input or a transformation that we want to perform. In other words, tree is an abstract set of operations, not a concrete set of output files.

In order to perform all the operations described in tree, we need to do the following:

construct a Builder instance, passing in the graph we constructed before
call the build method, which will traverse the graph, performing each operation and eventually writing the output to a temporary folder indicated by builder.outputPath
Since we typically want do more than write to a temporary folder, we'll also use a library called TreeSync to sync the contents of the temp file with our desired output directory. Finally, we'll clean up the temporary folder once all our operations are complete:

const { Builder } = require('broccoli');
const TreeSync = require('tree-sync');
const MergeTrees = require('broccoli-merge-trees');
// ...snip...
const tree = new MergeTrees([html, js, css, public]);

const builder = new Builder(tree);

const outputDir = 'dist';
const outputTree = new TreeSync(builder.outputPath, outputDir);

builder.build()
  .then(() => {
    // Calling `sync` will synchronize the contents of the builder's `outPath` with our output directory.
    return outputTree.sync();
  })
  .then(() => {
    // Now that we're done with the build, clean up any temporary files were created
    return builder.cleanup();
  })
  .catch(err => {
    // In case something in this process fails, we still want to ensure that we clean up the temp files
    console.log(err);
    return builder.cleanup();
  });
Running Broccoli, Directly or Through Other Tools
broccoli-timepiece
grunt-broccoli
grunt-broccoli-build
Helpers
Shared code for writing plugins.

broccoli-plugin
broccoli-caching-writer
broccoli-filter
Plugin API Specification
See docs/node-api.md.

Also see docs/broccoli-1-0-plugin-api.md on how to upgrade from Broccoli 0.x to the Broccoli 1.x API.

Security
Do not run broccoli serve on a production server. While this is theoretically safe, it exposes a needlessly large amount of attack surface just for serving static assets. Instead, use broccoli build to precompile your assets, and serve the static files from a web server of your choice.
Get Help
IRC: #broccolijs on Freenode. Ask your question and stick around for a few hours. Someone will see your message eventually.
Twitter: mention @jo_liss with your question
GitHub: Open an issue on a specific plugin repository, or on this repository for general questions.
License
Broccoli was originally written by Jo Liss and is licensed under the MIT license.

The Broccoli logo was created by Samantha Penner (Miric) and is licensed under CC0 1.0.


Brunch.

Brunch Weekly downloads Yearly downloads
Web applications made easy. Since 2011.

Fast front-end web app build tool with simple declarative config and seamless incremental compilation for rapid development.

Usage
Install Brunch with a simple node.js package manager command:

npm install -g brunch
Create a new Brunch project: brunch new [--skeleton url]
skeleton specifies a skeleton from which your application will be initialized. The default skeleton (dead-simple) doesn't have any opinions about frameworks or libraries.
brunch.io/skeletons contains over 50 boilerplate projects, which you can use to init your app from.
Develop with Brunch: brunch watch --server
tells Brunch to watch your project and incrementally rebuild it when source files are changed. The optional server flag launches a simple web server with push state support.
Deploy with Brunch: brunch build --production
builds a project for distribution. By default it enables minification.
Learn
Visit brunch.io
Read brunch docs

 #brunch tag
Contributing
See the CONTRIBUTING.md document for more info on how to file issues or get your head into the Brunch's internals.

To install edge version (from GitHub master branch): npm install -g brunch/brunch
To enable debug mode, simply pass -d flag to any command like that: brunch build -d
To create your own plugin, check out our plugin boilerplate as a starting point.
License
MIT license (c) 2021 Paul Miller paulmillr.com, Elan Shanker, Nik Graf, Thomas Schranz, Allan Berger, Jan Monschke, Martin Sch√ºrrer

See LICENSE file.


Fusebox.

LIMITED SUPPORT. USE AT YOUR OWN RISK


A bundler that does it right
Downloads Circle ci  npm version monthly downloads from npm code style: prettier
Backers on Open Collective Sponsors on Open Collective Follow FuseBox on Twitter

FuseBox on slack


FUSEBOX v4 is out!
Install:

npm install fuse-box --save-dev
import { fusebox } from 'fuse-box';
fusebox({
  target: 'browser',
  entry: 'src/index.tsx',
  webIndex: {
    template: 'src/index.html',
  },
  devServer: true,
}).runDev();
React demo.



Pkg.

pkg
[!IMPORTANT]
pkg has been deprecated with 5.8.1 as the last release. There are a number of successful forked versions of pkg already with various feature additions. Further, we‚Äôre excited about Node.js 21‚Äôs support for single executable applications. Thank you for the support and contributions over the years. The repository will remain open and archived.

This command line interface enables you to package your Node.js project into an executable that can be run even on devices without Node.js installed.

Use Cases
Make a commercial version of your application without sources
Make a demo/evaluation/trial version of your app without sources
Instantly make executables for other platforms (cross-compilation)
Make some kind of self-extracting archive or installer
No need to install Node.js and npm to run the packaged application
No need to download hundreds of files via npm install to deploy your application. Deploy it as a single file
Put your assets inside the executable to make it even more portable
Test your app against new Node.js version without installing it
Usage
npm install -g pkg
After installing it, run pkg --help without arguments to see list of options:

pkg [options] <input>

  Options:

    -h, --help output usage information
    -v, --version output pkg version
    -t, --targets comma-separated list of targets (see examples)
    -c, --config package.json or any json file with top-level config
    --options bake v8 options into executable to run with them on
    -o, --output output file name or template for several files
    --out-path path to save output one or more executables
    -d, --debug show more information during packaging process [off]
    -b, --build don't download prebuilt base binaries, build them
    --public speed up and disclose the sources of top-level project
    --public-packages force specified packages to be considered public
    --no-bytecode skip bytecode generation and include source files as plain js
    --no-native-build skip native addons build
    --no-signature skip signature of the final executable on macos
    --no-dict comma-separated list of packages names to ignore dictionaries. Use --no-dict * to disable all dictionaries
    -C, --compress [default=None] compression algorithm = Brotli or GZip

  Examples:

  ‚Äì Makes executables for Linux, macOS and Windows
    $ pkg index.js
  ‚Äì Takes package.json from cwd and follows 'bin' entry
    $ pkg .
  ‚Äì Makes executable for particular target machine
    $ pkg -t node16-win-arm64 index.js
  ‚Äì Makes executables for target machines of your choice
    $ pkg -t node16-linux,node18-linux,node16-win index.js
  ‚Äì Bakes '--expose-gc' and '--max-heap-size=34' into executable
    $ pkg --options "expose-gc,max-heap-size=34" index.js
  ‚Äì Consider packageA and packageB to be public
    $ pkg --public-packages "packageA,packageB" index.js
  ‚Äì Consider all packages to be public
    $ pkg --public-packages "*" index.js
  ‚Äì Bakes '--expose-gc' into executable
    $ pkg --options expose-gc index.js
  ‚Äì reduce size of the data packed inside the executable with GZip
    $ pkg --compress GZip index.js
The entrypoint of your project is a mandatory CLI argument. It may be:

Path to entry file. Suppose it is /path/app.js, then packaged app will work the same way as node /path/app.js
Path to package.json. Pkg will follow bin property of the specified package.json and use it as entry file.
Path to directory. Pkg will look for package.json in the specified directory. See above.
Targets
pkg can generate executables for several target machines at a time. You can specify a comma-separated list of targets via --targets option. A canonical target consists of 3 elements, separated by dashes, for example node18-macos-x64 or node14-linux-arm64:

nodeRange (node8), node10, node12, node14, node16 or latest
platform alpine, linux, linuxstatic, win, macos, (freebsd)
arch x64, arm64, (armv6, armv7)
(element) is unsupported, but you may try to compile yourself.

You may omit any element (and specify just node14 for example). The omitted elements will be taken from current platform or system-wide Node.js installation (its version and arch). There is also an alias host, that means that all 3 elements are taken from current platform/Node.js. By default targets are linux,macos,win for current Node.js version and arch.

If you want to generate executable for different architectures, note that by default pkg has to run the executable of the target arch to generate bytecodes:

Linux: configure binfmt with QEMU.
macOS: possible to build x64 on arm64 with Rosetta 2 but not opposite.
Windows: possible to build x64 on arm64 with x64 emulation but not opposite.
or, disable bytecode generation with --no-bytecode --public-packages "*" --public.
macos-arm64 is experimental. Be careful about the mandatory code signing requirement. The final executable has to be signed (ad-hoc signature is sufficient) with codesign utility of macOS (or ldid utility on Linux). Otherwise, the executable will be killed by kernel and the end-user has no way to permit it to run at all. pkg tries to ad-hoc sign the final executable. If necessary, you can replace this signature with your own trusted Apple Developer ID.

To be able to generate executables for all supported architectures and platforms, run pkg on a Linux host with binfmt (QEMU emulation) configured and ldid installed.

Config
During packaging process pkg parses your sources, detects calls to require, traverses the dependencies of your project and includes them into executable. In most cases you don't need to specify anything manually.

However your code may have require(variable) calls (so called non-literal argument to require) or use non-javascript files (for example views, css, images etc).

require('./build/' + cmd + '.js');
path.join(__dirname, 'views/' + viewName);
Such cases are not handled by pkg. So you must specify the files - scripts and assets - manually in pkg property of your package.json file.

  "pkg": {
    "scripts": "build/**/*.js",
    "assets": "views/**/*",
    "targets": [ "node14-linux-arm64" ],
    "outputPath": "dist"
  }
The above example will include everything in assets/ and every .js file in build/, build only for node14-linux-arm64, and place the executable inside dist/.

You may also specify arrays of globs:

    "assets": [ "assets/**/*", "images/**/*" ]
Just be sure to call pkg package.json or pkg . to make use of package.json configuration.

Scripts
scripts is a glob or list of globs. Files specified as scripts will be compiled using v8::ScriptCompiler and placed into executable without sources. They must conform to the JS standards of those Node.js versions you target (see Targets), i.e. be already transpiled.

Assets
assets is a glob or list of globs. Files specified as assets will be packaged into executable as raw content without modifications. Javascript files may also be specified as assets. Their sources will not be stripped as it improves execution performance of the files and simplifies debugging.

See also Detecting assets in source code and Snapshot filesystem.

Options
Node.js application can be called with runtime options (belonging to Node.js or V8). To list them type node --help or node --v8-options.

You can "bake" these runtime options into packaged application. The app will always run with the options turned on. Just remove -- from option name.

You can specify multiple options by joining them in a single string, comma (,) separated:

pkg app.js --options expose-gc
pkg app.js --options max_old_space_size=4096
pkg app.js --options max-old-space-size=1024,tls-min-v1.0,expose-gc
Output
You may specify --output if you create only one executable or --out-path to place executables for multiple targets.

Debug
Pass --debug to pkg to get a log of packaging process. If you have issues with some particular file (seems not packaged into executable), it may be useful to look through the log.

Bytecode (reproducibility)
By default, your source code is precompiled to v8 bytecode before being written to the output file. To disable this feature, pass --no-bytecode to pkg.

reproducible build process where your executable hashes (e.g. md5, sha1, sha256, etc.) are the same value between builds. Because compiling bytecode is not deterministic (see here or here) it results in executables with differing hashed values. Disabling bytecode compilation allows a given input to always have the same output.

While compiling to bytecode does not make your source code 100% secure, it does add a small layer of security/privacy/obscurity to your source code. Turning off bytecode compilation causes the raw source code to be written directly to the executable file. If you're on *nix machine and would like an example, run pkg with the --no-bytecode flag, and use the GNU strings tool on the output. You then should be able to grep your source code.

Other considerations
Specifying --no-bytecode will fail if there are any packages in your project that aren't explicitly marked as public by the license in their package.json. By default, pkg will check the license of each package and make sure that stuff that isn't meant for the public will only be included as bytecode.

If you do require building pkg binaries for other architectures and/or depend on a package with a broken license in its package.json, you can override this behaviour by either explicitly whitelisting packages to be public using --public-packages "packageA,packageB" or setting all packages to public using --public-packages "*"

Build
pkg has so called "base binaries" - they are actually same node executables but with some patches applied. They are used as a base for every executable pkg creates. pkg downloads precompiled base binaries before packaging your application. If you prefer to compile base binaries from source instead of downloading them, you may pass --build option to pkg. First ensure your computer meets the requirements to compile original Node.js: BUILDING.md

See pkg-fetch for more info.

Compression
Pass --compress Brotli or --compress GZip to pkg to compress further the content of the files store in the exectable.

This option can reduce the size of the embedded file system by up to 60%.

The startup time of the application might be reduced slightly.

-C can be used as a shortcut for --compress.

Environment
Var Description
PKG_CACHE_PATH Used to specify a custom path for node binaries cache folder. Default is ~/.pkg-cache
PKG_IGNORE_TAG Allows to ignore additional folder created on PKG_CACHE_PATH matching pkg-fetch version
MAKE_JOB_COUNT Allow configuring number of processes used for compiling
Examples

# 1 - Using export
export PKG_CACHE_PATH=/my/cache
pkg app.js

# 2 - Passing it before the script
PKG_CACHE_PATH=/my/cache pkg app.js
Usage of packaged app
Command line call to packaged app ./app a b is equivalent to node app.js a b

Snapshot filesystem
During packaging process pkg collects project files and places them into executable. It is called a snapshot. At run time the packaged application has access to snapshot filesystem where all that files reside.

Packaged files have /snapshot/ prefix in their paths (or C:\snapshot\ in Windows). If you used pkg /path/app.js command line, then __filename value will be likely /snapshot/path/app.js at run time. __dirname will be /snapshot/path as well. Here is the comparison table of path-related values:

value with node packaged comments
__filename /project/app.js /snapshot/project/app.js
__dirname /project /snapshot/project
process.cwd() /project /deploy suppose the app is called ...
process.execPath /usr/bin/nodejs /deploy/app-x64 app-x64 and run in /deploy
process.argv[0] /usr/bin/nodejs /deploy/app-x64
process.argv[1] /project/app.js /snapshot/project/app.js
process.pkg.entrypoint undefined /snapshot/project/app.js
process.pkg.defaultEntrypoint undefined /snapshot/project/app.js
require.main.filename /project/app.js /snapshot/project/app.js
Hence, in order to make use of a file collected at packaging time (require a javascript file or serve an asset) you should take __filename, __dirname, process.pkg.defaultEntrypoint or require.main.filename as a base for your path calculations. For javascript files you can just require or require.resolve because they use current __dirname by default. For assets use path.join(__dirname, '../path/to/asset'). Learn more about path.join in Detecting assets in source code.

On the other hand, in order to access real file system at run time (pick up a user's external javascript plugin, json configuration or even get a list of user's directory) you should take process.cwd() or path.dirname(process.execPath).

Detecting assets in source code
When pkg encounters path.join(__dirname, '../path/to/asset'), it automatically packages the file specified as an asset. See Assets. Pay attention that path.join must have two arguments and the last one must be a string literal.

This way you may even avoid creating pkg config for your project.

Native addons
Native addons (.node files) use is supported. When pkg encounters a .node file in a require call, it will package this like an asset. In some cases (like with the bindings package), the module path is generated dynamicaly and pkg won't be able to detect it. In this case, you should add the .node file directly in the assets field in package.json.

The way Node.js requires native addon is different from a classic JS file. It needs to have a file on disk to load it, but pkg only generates one file. To circumvent this, pkg will create a temporary file on the disk. These files will stay on the disk after the process has exited and will be used again on the next process launch.

When a package, that contains a native module, is being installed, the native module is compiled against current system-wide Node.js version. Then, when you compile your project with pkg, pay attention to --target option. You should specify the same Node.js version as your system-wide Node.js to make compiled executable compatible with .node files.

Note that fully static Node binaries are not capable of loading native bindings, so you may not use Node bindings with linuxstatic.

API
const { exec } = require('pkg')

exec(args) takes an array of command line arguments and returns a promise. For example:

await exec(['app.js', '--target', 'host', '--output', 'app.exe']);
// do something with app.exe, run, test, upload, deploy, etc
Troubleshooting
Error: ENOENT: no such file or directory, uv_chdir
This error can be caused by deleting the directory the application is run from. Or, generally, deleting process.cwd() directory when the application is running.

Error: ERR_INSPECTOR_NOT_AVAILABLE
This error can be caused by using NODE_OPTIONS variable to force to run node with the debug mode enabled. Debugging options are disallowed , as pkg executables are usually used for production environments. If you do need to use inspector, you can build a debuggable Node.js yourself.

Error: require(...).internalModuleStat is not a function
This error can be caused by using NODE_OPTIONS variable with some bootstrap or node options causing conflicts with pkg. Some IDEs, such as VS Code, may add this env variable automatically.

You could check on Unix systems (Linux/macOS) in bash:

$ printenv | grep NODE
Advanced
exploring virtual file system embedded in debug mode
When you are using the --debug flag when building your executable, pkg add the ability to display the content of the virtual file system and the symlink table on the console, when the application starts, providing that the environement variable DEBUG_PKG is set. This feature can be useful to inspect if symlinks are correctly handled, and check that all the required files for your application are properly incorporated to the final executable.

$ pkg --debug app.js -o output
$ DEBUG_PKG=1 output
or

C:\> pkg --debug app.js -o output.exe
C:\> set DEBUG_PKG=1
C:\> output.exe
Note: make sure not to use --debug flag in production.





